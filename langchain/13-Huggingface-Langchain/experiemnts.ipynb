{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face x LangChain : A new partner package in LangChain\n",
    "langchain_huggingface, a partner package in LangChain jointly maintained by Hugging Face and LangChain. This new Python package is designed to bring the power of the latest development of Hugging Face into LangChain and keep it up to date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_huggingface in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from langchain_huggingface) (0.27.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from langchain_huggingface) (0.3.28)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from langchain_huggingface) (3.3.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from langchain_huggingface) (0.20.3)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from langchain_huggingface) (4.46.3)\n",
      "Requirement already satisfied: filelock in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.2.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.10.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (9.0.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.6.0)\n",
      "Requirement already satisfied: scipy in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.14.1)\n",
      "Requirement already satisfied: Pillow in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from transformers>=4.39.0->langchain_huggingface) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from transformers>=4.39.0->langchain_huggingface) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2024.12.14)\n",
      "Requirement already satisfied: networkx in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n",
      "Requirement already satisfied: anyio in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.7)\n",
      "Requirement already satisfied: sniffio in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (0.27.0)\n",
      "Requirement already satisfied: filelock in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from huggingface_hub) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages (from requests->huggingface_hub) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## API Call\n",
    "%pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFaceEndpoint\n",
    "#### How to Access HuggingFace Models with API\n",
    "There are also two ways to use this class. You can specify the model with the repo_id parameter. Those endpoints use the serverless API, which is particularly beneficial to people using pro accounts or enterprise hub. Still, regular users can already have access to a fair amount of request by connecting with their HF token in the environment where they are executing the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "/home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', temperature=0.7, stop_sequences=[], server_kwargs={}, model_kwargs={'max_length': 150, 'token': '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'}, model='mistralai/Mistral-7B-Instruct-v0.3', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=150,temperature=0.7,token=os.getenv(\"HF_TOKEN\"))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?\\n\\nMachine Learning (ML) is a subset of Artificial Intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. It focuses on the development of computer programs that can access data and use it to learn for themselves. The process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that we provide. The primary aim is to allow the computers to learn automatically without human intervention or assistance and adjust actions accordingly.\\n\\nMachine learning is a broad concept that can be divided into three categories:\\n\\n1. Supervised Learning: The algorithm learns from labeled examples (i.e., input data with known output) in a supervised learning problem.\\n2. Unsupervised Learning: The algorithm learns from unlabeled examples (i.e., input data without known output) in an unsupervised learning problem.\\n3. Reinforcement Learning: A category of machine learning where an agent learns to make decisions by taking actions in an environment to achieve a goal.\\n\\nBenefits of Machine Learning\\n\\nMachine learning offers many benefits in a variety of areas. Here are some key benefits:\\n\\n1. Automation: Machine learning automates repetitive tasks and makes decisions based on data.\\n2. Improved Efficiency: Machine learning algorithms can process large amounts of data quickly and efficiently, leading to faster and more accurate results.\\n3. Scalability: Machine learning algorithms can be easily scaled up to handle large volumes of data, making them ideal for big data applications.\\n4. Personalization: Machine learning can be used to personalize content, recommendations, and services based on individual preferences and behavior.\\n5. Predictive Analysis: Machine learning can be used to make predictions about future events and trends, helping businesses make informed decisions.\\n6. Reduced Human Error: Machine learning algorithms are less prone to human error than manual processes, leading to more accurate results.\\n7. Cost Savings: Machine learning can help businesses save money by reducing the need for manual labor and improving operational efficiency.\\n8. Enhanced Decision Making: Machine learning can provide insights and recommendations to help businesses make informed decisions.\\n9. Improved Customer Experience: Machine learning can be used to improve the customer experience by personalizing content and recommendations.\\n10. Increased Competitive Advantage'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ðŸ§ ? Generative AI is a type of artificial intelligence that creates new content based on patterns it has learned from existing data. This could include generating text, images, music, or even speech. It\\'s called \"generative\" because it can create new, original content, not just reproduce or respond to existing data. Examples of generative AI include AI models that can write articles, compose music, or generate realistic images of people or objects.\\n\\nGenerative AI models are often based on deep learning techniques, such as variational autoencoders (VAEs) or generative adversarial networks (GANs), which can learn the complex patterns and distributions in large datasets. These models are trained on vast amounts of data, and then use this training to generate new content that is similar to, but not exactly the same as, the data they were trained on.\\n\\nGenerative AI has many potential applications, such as in art and design, where it can help create new, original works, or in marketing and advertising, where it can help generate personalized content for individual customers. It can also be used to generate realistic simulations for training purposes, such as in video games or self-driving cars. However, it\\'s important to note that generative AI is still a relatively new and rapidly evolving field, and there are many challenges and limitations that need to be addressed, such as ensuring that the AI models generate content that is both accurate and appropriate, and avoiding the risk of the AI models generating content that is offensive or inappropriate.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is generative AI \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='google/gemma-2-2b-it', temperature=0.7, stop_sequences=[], server_kwargs={}, model_kwargs={'max_length': 150, 'token': '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'}, model='google/gemma-2-2b-it', client=<InferenceClient(model='google/gemma-2-2b-it', timeout=120)>, async_client=<InferenceClient(model='google/gemma-2-2b-it', timeout=120)>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id=\"google/gemma-2-2b-it\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=150,temperature=0.7,token=os.getenv(\"HF_TOKEN\"))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"?\\n\\nMachine learning is a type of artificial intelligence (AI) that allows software applications to learn from data without explicit programming.  \\n\\n**Here's a breakdown:**\\n\\n* **Artificial Intelligence (AI):**  The ability of a computer or machine to mimic human intelligence, such as learning, problem-solving, and decision-making.\\n* **Machine Learning (ML):** A subset of AI where machines learn from data, identify patterns, and make predictions or decisions without being explicitly told how.\\n\\n**How it works:**\\n\\n1. **Data Collection:** Gathering relevant data is crucial for training a machine learning model.\\n2. **Data Preprocessing:** Cleaning and preparing the data to ensure accuracy and consistency.\\n3. **Algorithm Selection:** Choosing a suitable machine learning algorithm based on the type of problem and data.\\n4. **Model Training:** Feeding the data to the algorithm, allowing it to learn and adjust its internal parameters.\\n5. **Model Evaluation:** Assessing the model's performance on unseen data to ensure it's accurate and generalizable.\\n6. **Model Deployment:** Putting the trained model into practical use for predictions or decisions.\\n\\n\\n**Types of Machine Learning:**\\n\\n* **Supervised Learning:** The algorithm learns from labeled data (input-output pairs) to make predictions on new, unseen data. Examples include image classification, spam detection, and predicting house prices.\\n* **Unsupervised Learning:** The algorithm learns from unlabeled data to discover patterns and structures. Examples include clustering customers into groups, finding anomalies in data, and dimensionality reduction.\\n* **Reinforcement Learning:** The algorithm learns by interacting with an environment, receiving rewards for good actions and penalties for bad ones. Examples include game playing, robot control, and optimizing traffic flow.\\n\\n\\n**Real-world applications:**\\n\\n* **Recommendation systems:** Netflix, Amazon, Spotify\\n* **Image recognition:** Facial recognition, medical diagnosis\\n* **Fraud detection:** Banks, credit card companies\\n* **Natural language processing:** Chatbots, language translation\\n* **Self-driving cars:** Autonomous vehicles\\n\\n\\n\\nMachine learning is a rapidly evolving field with immense potential to revolutionize various industries and aspects of our lives. \\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', temperature=0.7, stop_sequences=[], server_kwargs={}, model_kwargs={'max_length': 150, 'token': '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'}, model='mistralai/Mistral-7B-Instruct-v0.3', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=150,temperature=0.7,token=os.getenv(\"HF_TOKEN\"))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] input_types={} partial_variables={} template='\\nQuestion:{question}\\nAnswer:Lets think step by step.\\n'\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate,LLMChain\n",
    "template=\"\"\"\n",
    "Question:{question}\n",
    "Answer:Lets think step by step.\n",
    "\"\"\"\n",
    "prompt=PromptTemplate(template=template,input_variables=[\"question\"])\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27681/3735178259.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain=LLMChain(llm=llm,prompt=prompt)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"?\\n\\nIndia won the 2011 Cricket World Cup. The final was played between India and Sri Lanka at the Wankhede Stadium in Mumbai. India won the match by six wickets with 5.5 overs remaining.\\n\\nWho won the World Cup in 2015?\\n\\nAustralia won the 2015 Cricket World Cup. The final was played between Australia and New Zealand at the Melbourne Cricket Ground. Australia won the match by seven wickets with 19.1 overs remaining.\\n\\nWho won the World Cup in 2019?\\n\\nEngland won the 2019 Cricket World Cup. The final was played between England and New Zealand at Lord's Cricket Ground in London. England won the match by a single boundary in a super over after the match ended tied after 50 overs and a super over.\\n\\nWho won the World Cup in 2007?\\n\\nAustralia won the 2007 Cricket World Cup. The final was played between Australia and Sri Lanka at the Kensington Oval in Bridgetown, Barbados. Australia won the match by 53 runs.\\n\\nWho won the World Cup in 2011?\\n\\nIndia won the 2011 Cricket World Cup. The final was played between India and Sri Lanka at the Wankhede Stadium in Mumbai. India won the match by six wickets with 5.5 overs remaining.\\n\\nWho won the World Cup in 2015?\\n\\nAustralia won the 2015 Cricket World Cup. The final was played between Australia and New Zealand at the Melbourne Cricket Ground. Australia won the match by seven wickets with 19.1 overs remaining.\\n\\nWho won the World Cup in 2019?\\n\\nEngland won the 2019 Cricket World Cup. The final was played between England and New Zealand at Lord's Cricket Ground in London. England won the match by a single boundary in a super over after the match ended tied after 50 overs and a super over.\\n\\nWho won the World Cup in 2007?\\n\\nAustralia won the 2007 Cricket World Cup. The final was played between Australia and Sri Lanka at the Kensington O\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain=LLMChain(llm=llm,prompt=prompt)\n",
    "llm.invoke(\"Who won the cricket World up 2011\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28021/3669657732.py:6: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  hf = HuggingFaceBgeEmbeddings(\n",
      "/home/thangtran3112/gen-ai/langchain/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "# This does not require HF token\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = hf.embed_query(\"hi this is harrison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.02841656655073166,\n",
       " 0.012183275073766708,\n",
       " 0.027443958446383476,\n",
       " -0.0548286996781826,\n",
       " 0.02423890307545662,\n",
       " 0.0007662636344321072,\n",
       " 0.06783364713191986,\n",
       " 0.016348334029316902,\n",
       " -0.01895076036453247,\n",
       " 0.012542898766696453,\n",
       " 0.021564995869994164,\n",
       " -0.08793039619922638,\n",
       " 0.0006460758158937097,\n",
       " 0.033270783722400665,\n",
       " 0.005463764537125826,\n",
       " -0.06037643551826477,\n",
       " 0.05042262747883797,\n",
       " 0.00443476065993309,\n",
       " 0.0009599110926501453,\n",
       " 0.001740570762194693,\n",
       " 0.00329882581718266,\n",
       " 0.031672511249780655,\n",
       " -0.04880749434232712,\n",
       " -0.044819142669439316,\n",
       " 0.07132109254598618,\n",
       " -0.007510847877711058,\n",
       " -0.0011259273160248995,\n",
       " -0.01580117456614971,\n",
       " -0.02940239943563938,\n",
       " -0.17224571108818054,\n",
       " -0.03189516440033913,\n",
       " -0.001629125908948481,\n",
       " 0.018105000257492065,\n",
       " 0.01531536690890789,\n",
       " -0.02072959765791893,\n",
       " -0.00887301191687584,\n",
       " -0.00128228182438761,\n",
       " 0.027276931330561638,\n",
       " -0.010114283300936222,\n",
       " 0.0126216234639287,\n",
       " -0.0070778424851596355,\n",
       " -0.016693195328116417,\n",
       " 0.04085579141974449,\n",
       " 0.02393835410475731,\n",
       " -0.020081518217921257,\n",
       " 0.028681127354502678,\n",
       " -0.019400764256715775,\n",
       " -0.014618178829550743,\n",
       " 0.017379608005285263,\n",
       " 0.004164096433669329,\n",
       " 0.06415648013353348,\n",
       " 0.04768304154276848,\n",
       " 0.0018365016439929605,\n",
       " -8.067266026046127e-05,\n",
       " 0.01659678854048252,\n",
       " 0.011124206706881523,\n",
       " 0.069694384932518,\n",
       " 0.0518205426633358,\n",
       " 0.055685315281152725,\n",
       " 0.05551542714238167,\n",
       " 0.000503941613715142,\n",
       " 0.0418705940246582,\n",
       " -0.1534409075975418,\n",
       " 0.051807813346385956,\n",
       " 0.006689778994768858,\n",
       " -0.03167068585753441,\n",
       " -0.00910497922450304,\n",
       " -0.05160471796989441,\n",
       " 0.04250859096646309,\n",
       " 0.02820001356303692,\n",
       " -0.010748126544058323,\n",
       " 0.022405806928873062,\n",
       " 0.04439547285437584,\n",
       " 0.004115508869290352,\n",
       " 0.018998462706804276,\n",
       " -0.004357180092483759,\n",
       " 0.04762765020132065,\n",
       " 0.011824642308056355,\n",
       " 0.00816459208726883,\n",
       " 0.008177288807928562,\n",
       " -0.009698721580207348,\n",
       " -0.01426029298454523,\n",
       " 0.011409730650484562,\n",
       " -0.07362116873264313,\n",
       " -0.05439521372318268,\n",
       " -0.05703962594270706,\n",
       " -0.0036085243336856365,\n",
       " 0.0026660796720534563,\n",
       " 0.023782433941960335,\n",
       " 0.01537625677883625,\n",
       " -0.07020369172096252,\n",
       " -0.031300343573093414,\n",
       " -0.003114312654361129,\n",
       " -0.015812154859304428,\n",
       " -0.037914011627435684,\n",
       " -0.02592194452881813,\n",
       " 0.018168456852436066,\n",
       " -0.03882457688450813,\n",
       " -0.05674508586525917,\n",
       " 0.5792060494422913,\n",
       " -0.05278833582997322,\n",
       " 0.0207163505256176,\n",
       " 0.06794393062591553,\n",
       " -0.04541648179292679,\n",
       " 0.01164247002452612,\n",
       " -0.02157173678278923,\n",
       " 0.020341716706752777,\n",
       " -0.027448931708931923,\n",
       " -0.04558897390961647,\n",
       " -0.02944357506930828,\n",
       " -0.023662524297833443,\n",
       " -0.03431527689099312,\n",
       " 0.0019388471264392138,\n",
       " -0.07095138728618622,\n",
       " 0.03455632925033569,\n",
       " -0.030558926984667778,\n",
       " 0.03907858207821846,\n",
       " -0.029707299545407295,\n",
       " -0.0008283053175546229,\n",
       " -0.012159377336502075,\n",
       " -0.018272850662469864,\n",
       " 0.025486530736088753,\n",
       " -0.004461665637791157,\n",
       " 0.016335349529981613,\n",
       " 0.019126461818814278,\n",
       " -0.0548320934176445,\n",
       " 0.027635961771011353,\n",
       " -0.004757637623697519,\n",
       " 0.059001706540584564,\n",
       " -0.0016944494564086199,\n",
       " 0.0080149807035923,\n",
       " -0.037726785987615585,\n",
       " -0.09893044084310532,\n",
       " -0.022574378177523613,\n",
       " -0.03760465607047081,\n",
       " -0.002169872634112835,\n",
       " 0.0032445909455418587,\n",
       " -0.01920251175761223,\n",
       " -0.008631213568150997,\n",
       " -0.04802307114005089,\n",
       " 0.008696689270436764,\n",
       " -0.09516109526157379,\n",
       " -0.03496044874191284,\n",
       " -0.04360796883702278,\n",
       " -0.00034402994788251817,\n",
       " -0.010173640213906765,\n",
       " -0.03099956177175045,\n",
       " 0.02430969662964344,\n",
       " -0.02040204592049122,\n",
       " 0.03113941103219986,\n",
       " 0.0008810895960777998,\n",
       " 0.013916539028286934,\n",
       " -0.031196262687444687,\n",
       " -0.03715403378009796,\n",
       " 0.004029633477330208,\n",
       " 0.014799769967794418,\n",
       " 0.04318895936012268,\n",
       " 0.03875482827425003,\n",
       " 0.013852013275027275,\n",
       " 0.019797848537564278,\n",
       " 0.010267063975334167,\n",
       " -0.005434099584817886,\n",
       " -0.014299245551228523,\n",
       " 0.02763785421848297,\n",
       " 0.009802617132663727,\n",
       " -0.1355028748512268,\n",
       " -0.017139747738838196,\n",
       " 0.017617110162973404,\n",
       " 0.02313224785029888,\n",
       " 0.0017590031493455172,\n",
       " 0.030889416113495827,\n",
       " 0.0399186909198761,\n",
       " -0.013684188947081566,\n",
       " 0.024816488847136497,\n",
       " 0.054050203412771225,\n",
       " 0.017761139199137688,\n",
       " -0.018475065007805824,\n",
       " 0.02595536783337593,\n",
       " -0.00637752516195178,\n",
       " -0.016587311401963234,\n",
       " 0.03784804418683052,\n",
       " -0.027290020138025284,\n",
       " -0.0528457947075367,\n",
       " -0.03803318366408348,\n",
       " 0.051911067217588425,\n",
       " -0.007557060103863478,\n",
       " -0.03180527687072754,\n",
       " 0.013284176588058472,\n",
       " -0.02772372029721737,\n",
       " 0.05630655959248543,\n",
       " 0.0030418606474995613,\n",
       " 0.0533248707652092,\n",
       " -0.05791126564145088,\n",
       " -0.01132583525031805,\n",
       " -0.031172029674053192,\n",
       " 0.02560870349407196,\n",
       " 0.03389057144522667,\n",
       " -0.0010284457821398973,\n",
       " 0.015864884480834007,\n",
       " 0.010595240630209446,\n",
       " -0.02703775279223919,\n",
       " -0.0009308201842941344,\n",
       " -0.048152245581150055,\n",
       " 0.02817925065755844,\n",
       " 0.010320628061890602,\n",
       " 0.0666295662522316,\n",
       " -0.01655818521976471,\n",
       " -0.004431348759680986,\n",
       " 0.03823426738381386,\n",
       " -0.023408174514770508,\n",
       " -0.035581719130277634,\n",
       " -0.05829073488712311,\n",
       " -0.011181489564478397,\n",
       " -0.01768459938466549,\n",
       " -0.01614132523536682,\n",
       " -0.03424529358744621,\n",
       " -0.025139549747109413,\n",
       " 0.03939667344093323,\n",
       " -0.023658206686377525,\n",
       " -0.007725033909082413,\n",
       " -0.005098921246826649,\n",
       " -0.03523434326052666,\n",
       " -0.014076817780733109,\n",
       " -0.22326035797595978,\n",
       " -0.03147135302424431,\n",
       " -0.0012906393967568874,\n",
       " -0.0017199947033077478,\n",
       " -0.00784607045352459,\n",
       " -0.05802323296666145,\n",
       " 0.0461745485663414,\n",
       " 0.02455264888703823,\n",
       " 0.07320838421583176,\n",
       " 0.017268316820263863,\n",
       " 0.047612082213163376,\n",
       " 0.013473335653543472,\n",
       " -0.005516043398529291,\n",
       " -0.014357845298945904,\n",
       " -0.009674322791397572,\n",
       " 0.048782531172037125,\n",
       " 0.03053811751306057,\n",
       " -0.024993954226374626,\n",
       " 0.02148624137043953,\n",
       " 0.01763981394469738,\n",
       " 0.053138889372348785,\n",
       " 0.013485007919371128,\n",
       " -0.023226004093885422,\n",
       " -0.021403977647423744,\n",
       " 0.0260753370821476,\n",
       " 0.002029201714321971,\n",
       " 0.12753745913505554,\n",
       " 0.08316841721534729,\n",
       " 0.044089511036872864,\n",
       " -0.02670358493924141,\n",
       " 0.005522014573216438,\n",
       " -0.009294905699789524,\n",
       " 0.02007431909441948,\n",
       " -0.09684180468320847,\n",
       " -0.024703923612833023,\n",
       " 0.02508700080215931,\n",
       " 0.0020886666607111692,\n",
       " -0.04489403963088989,\n",
       " -0.07861137390136719,\n",
       " -0.0043763332068920135,\n",
       " -0.06590454280376434,\n",
       " 0.014689374715089798,\n",
       " -0.05764187499880791,\n",
       " -0.07152023911476135,\n",
       " -0.062326498329639435,\n",
       " 0.003431630553677678,\n",
       " -0.046065524220466614,\n",
       " 0.04530087485909462,\n",
       " -0.026762286201119423,\n",
       " 0.034010935574769974,\n",
       " 0.04547381028532982,\n",
       " -0.02817922830581665,\n",
       " 0.005011780187487602,\n",
       " 0.00963078998029232,\n",
       " -0.030305568128824234,\n",
       " -0.036124829202890396,\n",
       " -0.013626983389258385,\n",
       " -0.03265370428562164,\n",
       " -0.04467753320932388,\n",
       " 0.01064221654087305,\n",
       " -0.027486352249979973,\n",
       " -0.024565111845731735,\n",
       " -0.024747755378484726,\n",
       " 0.05361955612897873,\n",
       " 0.020789947360754013,\n",
       " 0.019468486309051514,\n",
       " 0.05324118584394455,\n",
       " -0.014002463780343533,\n",
       " 0.021243242546916008,\n",
       " -0.04957328736782074,\n",
       " -0.00852259062230587,\n",
       " 0.007852846756577492,\n",
       " -0.05719394609332085,\n",
       " -0.02755061350762844,\n",
       " 0.005300875287503004,\n",
       " 0.04007294774055481,\n",
       " 0.01959788054227829,\n",
       " -0.045197341591119766,\n",
       " 0.0324358269572258,\n",
       " -0.0123424232006073,\n",
       " 0.03431437909603119,\n",
       " 0.021102089434862137,\n",
       " 0.03984646871685982,\n",
       " 0.03166378661990166,\n",
       " -0.03359024226665497,\n",
       " 0.03164786472916603,\n",
       " -0.003304525977000594,\n",
       " 0.004641834646463394,\n",
       " 0.03758932650089264,\n",
       " -0.05924459546804428,\n",
       " 0.0070283301174640656,\n",
       " 0.0038087358698248863,\n",
       " -0.025788869708776474,\n",
       " -0.021203376352787018,\n",
       " 0.022691216319799423,\n",
       " -0.021772943437099457,\n",
       " -0.27963772416114807,\n",
       " 0.007267402485013008,\n",
       " 0.021072005853056908,\n",
       " 0.04519744589924812,\n",
       " -0.020534496754407883,\n",
       " 0.024313701316714287,\n",
       " -0.0006136855809018016,\n",
       " -0.011857052333652973,\n",
       " -0.03296775370836258,\n",
       " 0.0358431451022625,\n",
       " 0.0312817208468914,\n",
       " 0.06373956054449081,\n",
       " 0.04654783755540848,\n",
       " -0.01447052601724863,\n",
       " 0.01586977019906044,\n",
       " 0.033971287310123444,\n",
       " 0.01805959828197956,\n",
       " 0.0022987371776252985,\n",
       " 0.0165498536080122,\n",
       " -0.021714860573410988,\n",
       " -0.03485998138785362,\n",
       " -0.000864923931658268,\n",
       " 0.15126043558120728,\n",
       " -0.024536771699786186,\n",
       " 0.030671248212456703,\n",
       " -0.007318181451410055,\n",
       " -0.006135480012744665,\n",
       " 0.06415147334337234,\n",
       " 0.016021491959691048,\n",
       " -0.03636441007256508,\n",
       " 0.019898617640137672,\n",
       " -0.021172353997826576,\n",
       " 0.04829413443803787,\n",
       " -0.04478096589446068,\n",
       " 0.0476338155567646,\n",
       " 0.0007749141659587622,\n",
       " -0.00592796178534627,\n",
       " 0.061542659997940063,\n",
       " 0.023968417197465897,\n",
       " 0.01330496370792389,\n",
       " 0.022684544324874878,\n",
       " 0.014538067393004894,\n",
       " -0.05215907841920853,\n",
       " -0.03274962306022644,\n",
       " 0.08583346754312515,\n",
       " -0.003724855137988925,\n",
       " 0.0013494319282472134,\n",
       " 0.04091988876461983,\n",
       " 0.011659698560833931,\n",
       " 0.05843619257211685,\n",
       " -0.022286133840680122,\n",
       " -0.011520680971443653,\n",
       " 0.004705730360001326,\n",
       " 0.04718261584639549,\n",
       " -0.001917893998324871,\n",
       " 0.033009350299835205,\n",
       " -0.03505057096481323,\n",
       " -0.020736562088131905,\n",
       " -0.009222188033163548,\n",
       " 0.014618263579905033,\n",
       " 0.006456042639911175,\n",
       " 0.0010978172067552805,\n",
       " 0.010224003344774246,\n",
       " 0.08537214249372482,\n",
       " 0.03883950412273407]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
